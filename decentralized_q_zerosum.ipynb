{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hafezgh/MSc-Thesis/blob/main/decentralized_q_zerosum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qkRst1OiIpa"
      },
      "source": [
        "The Python code implementing Decentralized Q-learning Dynamics proposed in:\n",
        "\n",
        "Sayin, Muhammed, et al. \"Decentralized Q-learning in zero-sum Markov games.\" Advances in Neural Information Processing Systems 34 (2021)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYW359-KiIpf"
      },
      "source": [
        "# Experiment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-7hJFeQuiIpg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(0)\n",
        "n_actions = 3\n",
        "n_states = 5\n",
        "n_players = 2\n",
        "init_state = np.random.randint(0,n_states)\n",
        "current_state = init_state\n",
        "next_state = None\n",
        "rho = 0.7\n",
        "rho_alpha = 0.9\n",
        "rho_beta = 1.0\n",
        "gamma = 0.6\n",
        "D = 1/(1-gamma)\n",
        "n_trials = 5\n",
        "n_iters = int(1*1e7+1)\n",
        "eps = 0.0002\n",
        "tau = 2.0*np.ones((n_states))\n",
        "\n",
        "\n",
        "\n",
        "q1 = np.zeros((n_states,n_actions))\n",
        "q2 = np.zeros((n_states,n_actions))\n",
        "\n",
        "v1 = np.zeros((n_states))\n",
        "v2 = np.zeros((n_states))\n",
        "vsum = np.zeros((n_states))\n",
        "\n",
        "\n",
        "v1_mean = np.zeros((n_iters, n_states))\n",
        "v2_mean = np.zeros((n_iters, n_states))\n",
        "v_sum_mean = np.zeros((n_iters, n_states))\n",
        "\n",
        "count_states = np.zeros((n_states), dtype=int)\n",
        "\n",
        "\n",
        "S = np.array(list(range(n_states)), dtype=int)\n",
        "A = np.array(list(range(n_actions)), dtype=int)\n",
        "\n",
        "\n",
        "P = np.zeros((n_states,n_actions,n_actions, n_states))\n",
        "R1 = np.zeros((n_states,n_actions,n_actions))\n",
        "R2 = np.zeros((n_states,n_actions,n_actions))\n",
        "\n",
        "a1 = np.random.choice(A)\n",
        "a2 = np.random.choice(A)\n",
        "\n",
        "r1 = 0.\n",
        "r2 = 0.\n",
        "\n",
        "pi_bar1 = np.ones((n_actions))\n",
        "pi_bar1/=np.sum(pi_bar1)\n",
        "pi_bar2 = np.ones((n_actions))\n",
        "pi_bar2/=np.sum(pi_bar2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hUVjyhv0iIpj"
      },
      "outputs": [],
      "source": [
        "# Define states, transition matrix, rewards\n",
        "for i in range(len(S)):\n",
        "    for j in range(len(A)):\n",
        "        for k in range(len(A)):\n",
        "            P[i, j, k, :] = np.random.uniform(0,1,(n_states)) + 0.01\n",
        "            P[i, j, k, :] /= np.sum(P[i, j, k, :])\n",
        "\n",
        "for i in range(len(S)):\n",
        "    R1[i,:,:] = np.random.uniform(-1,1,(n_actions,n_actions))*np.exp(S[i]**2)\n",
        "    R2[i,:,:] = -R1[i,:,:]\n",
        "\n",
        "    max_r = np.max(abs(R1[i,:,:]))\n",
        "    R1[i,:,:] /= max_r\n",
        "    R2[i,:,:] /= max_r\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6ew3yeiiIpk"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "o0BmdTbgiIpk"
      },
      "outputs": [],
      "source": [
        "def tau_decay_to_zero(count_state, rho_alpha,rho,D):\n",
        "    tau_bar = 0.068\n",
        "    return tau_bar/(1+(tau_bar*rho_alpha*rho*np.log(count_state))/(4*D))\n",
        "\n",
        "def tau_decay_to_eps(count_state, eps):\n",
        "    #tau_bar = 45000\n",
        "    tau_bar = 4500\n",
        "    return (1/count_state)*tau_bar+(1-1/count_state)*eps\n",
        "\n",
        "def compute_alpha(count_state, rho_alpha):\n",
        "    C = 1.5\n",
        "    return C*1/pow(count_state,rho_alpha)\n",
        "\n",
        "def compute_beta(count_state, rho_beta):\n",
        "    C = 1.5\n",
        "    return C*1/pow(count_state,rho_beta)\n",
        "\n",
        "def softmax(arr):\n",
        "    probs = np.exp(arr)/np.sum(np.exp(arr))\n",
        "    return np.argmax(probs), np.max(probs), probs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm4Om1egiIpl"
      },
      "source": [
        "# Run the experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ttqZO09UiIpm"
      },
      "outputs": [],
      "source": [
        "counter = 0\n",
        "for trial in range(n_trials):\n",
        "    init_state = np.random.randint(0,n_states)\n",
        "    current_state = init_state\n",
        "    \n",
        "    next_state = None\n",
        "    tau = 2.0*np.ones((n_states))\n",
        "    q1 = np.zeros((n_states,n_actions))\n",
        "    q2 = np.zeros((n_states,n_actions))\n",
        "    v1 = np.zeros((n_states))\n",
        "    v2 = np.zeros((n_states))\n",
        "    vsum = np.zeros((n_states))\n",
        "    \n",
        "    v1_hist = np.zeros((n_iters, n_states))\n",
        "    v2_hist = np.zeros((n_iters, n_states))\n",
        "    vsum_hist = np.zeros((n_iters, n_states))\n",
        "    \n",
        "\n",
        "    count_states = np.zeros((n_states), dtype=int)\n",
        "    print('trial:', trial+1)\n",
        "    \n",
        "    for iter in range(n_iters):\n",
        "        count_states[current_state] += 1\n",
        "        \n",
        "        if iter % int(1e5) == 0 and iter!=0:\n",
        "            print(\"iteration:\", iter)\n",
        "\n",
        "        # take actions and update tau\n",
        "        a1, a1_prob, pi_bar1 = softmax(q1[current_state,:]/tau[current_state])\n",
        "        a2, a2_prob, pi_bar2 = softmax(q2[current_state,:]/tau[current_state])\n",
        "\n",
        "        ## Decay to epsilone\n",
        "        tau[current_state] = tau_decay_to_eps(count_states[current_state], eps)\n",
        "\n",
        "        # Decay to zero\n",
        "        #tau[current_state] = tau_decay_to_zero(count_states[current_state], rho_alpha,rho, D)\n",
        "\n",
        "        # calculate rewards\n",
        "        r1 = R1[current_state, a1, a2]\n",
        "        r2 = R2[current_state, a1, a2]\n",
        "\n",
        "        # next state\n",
        "        next_state = np.random.choice(list(range(n_states)),p=P[current_state, a1, a2, :])\n",
        "\n",
        "        # calculate learning rates (alpha and beta)\n",
        "        alpha_bar1 = min(1, compute_alpha(count_states[current_state],rho_alpha)/a1_prob)\n",
        "        alpha_bar2 = min(1, compute_alpha(count_states[current_state],rho_alpha)/a2_prob)\n",
        "        beta = compute_beta(count_states[current_state], rho_beta)\n",
        "\n",
        "        # update local q-function and value functions\n",
        "        q1[current_state, a1] = q1[current_state, a1] + alpha_bar1*(r1+gamma*v1[next_state]-q1[current_state,a1])\n",
        "        v1[current_state] = v1[current_state] + beta*(a1_prob*q1[current_state, a1]-v1[current_state])\n",
        "\n",
        "        q2[current_state, a2] = q2[current_state, a2] + alpha_bar2*(r2+gamma*v2[next_state]-q2[current_state,a2])\n",
        "        v2[current_state] = v2[current_state] + beta*(a2_prob*q2[current_state, a2]-v2[current_state])\n",
        "        \n",
        "        v1_hist[iter,:] = v1\n",
        "        v2_hist[iter,:] = v2\n",
        "        vsum = v1+v2\n",
        "        vsum_hist[iter, :] = vsum\n",
        "        current_state = copy.deepcopy(next_state)\n",
        "\n",
        "    v1_mean = (v1_mean*counter + np.array(v1_hist))/(counter+1)\n",
        "    v2_mean = (v2_mean*counter + np.array(v2_hist))/(counter+1)\n",
        "    v_sum_mean = (v_sum_mean*counter + np.array(vsum_hist))/(counter+1)\n",
        "    counter+=1\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SgqahrgiIpn"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWEOpDlRiIpn"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "ax.plot(list(range(n_iters)),v1_mean[:,0], color='red')\n",
        "ax.plot(list(range(n_iters)),v1_mean[:,1], color='blue')\n",
        "ax.plot(list(range(n_iters)),v1_mean[:,2], color='pink')\n",
        "ax.plot(list(range(n_iters)),v1_mean[:,3], color='green')\n",
        "ax.plot(list(range(n_iters)),v1_mean[:,4], color='orange')\n",
        "\n",
        "ax.plot(list(range(n_iters)),v2_mean[:,0], color='red')\n",
        "ax.plot(list(range(n_iters)),v2_mean[:,1], color='blue')\n",
        "ax.plot(list(range(n_iters)),v2_mean[:,2], color='pink')\n",
        "ax.plot(list(range(n_iters)),v2_mean[:,3], color='green')\n",
        "ax.plot(list(range(n_iters)),v2_mean[:,4], color='orange')\n",
        "\n",
        "ax.plot(list(range(n_iters)),v_sum_mean[:,0], color='black')\n",
        "ax.plot(list(range(n_iters)),v_sum_mean[:,1], color='black')\n",
        "ax.plot(list(range(n_iters)),v_sum_mean[:,2], color='black')\n",
        "ax.plot(list(range(n_iters)),v_sum_mean[:,3], color='black')\n",
        "ax.plot(list(range(n_iters)),v_sum_mean[:,4], color='black')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "decentralized_q_zerosum.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "39944124f9b5d60d862a3cf40ea9b11aa8e952b3995fe09a01f412de3b98a252"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
